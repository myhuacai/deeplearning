{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5 2.5 3. ]\n",
      " [4.  4.5 4.5]]\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵\n",
    "#cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y,1e-10,1.0))\n",
    "#                               + (1-y_)*tf.log(tf.clip_by_value(1-y,1e-10,1.0)))\n",
    "# tf.clip_by_value()函数可以将一个张量中的数值限制在一个范围内，利用这个函数可以保证在进行log运算时，\n",
    "# 不会出现log0这样的错误，或者概率大于1的错误\n",
    "v = tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.clip_by_value(v,2.5,4.5)))\n",
    "# 将小于2.5的替换成2.5，将大于4.5的替换成4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul_4:0\", shape=(2, 2), dtype=float32)\n",
      "Tensor(\"MatMul_3:0\", shape=(2, 2), dtype=float32)\n",
      "[[ 5. 12.]\n",
      " [21. 32.]]\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n"
     ]
    }
   ],
   "source": [
    "# 相乘与内积\n",
    "v1 = tf.constant([[1.0,2.0],[3.0,4.0]])\n",
    "v2 = tf.constant([[5.0,6.0],[7.0,8.0]])\n",
    "print(v1*v2) # 相乘  mul\n",
    "print(tf.matmul(v1,v2)) # 矩阵乘法 内积 matmul\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(v1*v2))\n",
    "    print(sess.run(tf.matmul(v1,v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "# 取均值，因上面得到的交叉熵是1个batch的，需要平均下，取这个batch的平均交叉熵作为结果\n",
    "v3 = tf.constant([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reduce_mean(v3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow有实现cross_entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=,logits=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[4. 3. 3. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# 自定义损失函数\n",
    "v1 = tf.constant([1.0,2.0,3.0,4.0])\n",
    "v2 = tf.constant([4.0,3.0,2.0,1.0])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(tf.greater(v1,v2).eval())\n",
    "# [False False  True  True]\n",
    "print(tf.where(tf.greater(v1,v2),v1,v2).eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.17022005e-01, 7.20324493e-01],\n",
       "       [1.14374817e-04, 3.02332573e-01],\n",
       "       [1.46755891e-01, 9.23385948e-02],\n",
       "       [1.86260211e-01, 3.45560727e-01],\n",
       "       [3.96767474e-01, 5.38816734e-01],\n",
       "       [4.19194514e-01, 6.85219500e-01],\n",
       "       [2.04452250e-01, 8.78117436e-01],\n",
       "       [2.73875932e-02, 6.70467510e-01],\n",
       "       [4.17304802e-01, 5.58689828e-01],\n",
       "       [1.40386939e-01, 1.98101489e-01],\n",
       "       [8.00744569e-01, 9.68261576e-01],\n",
       "       [3.13424178e-01, 6.92322616e-01],\n",
       "       [8.76389152e-01, 8.94606664e-01],\n",
       "       [8.50442114e-02, 3.90547832e-02],\n",
       "       [1.69830420e-01, 8.78142503e-01],\n",
       "       [9.83468338e-02, 4.21107625e-01],\n",
       "       [9.57889530e-01, 5.33165285e-01],\n",
       "       [6.91877114e-01, 3.15515631e-01],\n",
       "       [6.86500928e-01, 8.34625672e-01],\n",
       "       [1.82882773e-02, 7.50144315e-01],\n",
       "       [9.88861089e-01, 7.48165654e-01],\n",
       "       [2.80443992e-01, 7.89279328e-01],\n",
       "       [1.03226007e-01, 4.47893526e-01],\n",
       "       [9.08595503e-01, 2.93614148e-01],\n",
       "       [2.87775339e-01, 1.30028572e-01],\n",
       "       [1.93669579e-02, 6.78835533e-01],\n",
       "       [2.11628116e-01, 2.65546659e-01],\n",
       "       [4.91573159e-01, 5.33625451e-02],\n",
       "       [5.74117605e-01, 1.46728575e-01],\n",
       "       [5.89305537e-01, 6.99758360e-01],\n",
       "       [1.02334429e-01, 4.14055988e-01],\n",
       "       [6.94400158e-01, 4.14179270e-01],\n",
       "       [4.99534589e-02, 5.35896406e-01],\n",
       "       [6.63794645e-01, 5.14889112e-01],\n",
       "       [9.44594756e-01, 5.86555041e-01],\n",
       "       [9.03401915e-01, 1.37474704e-01],\n",
       "       [1.39276347e-01, 8.07391289e-01],\n",
       "       [3.97676837e-01, 1.65354197e-01],\n",
       "       [9.27508580e-01, 3.47765860e-01],\n",
       "       [7.50812103e-01, 7.25997985e-01],\n",
       "       [8.83306091e-01, 6.23672207e-01],\n",
       "       [7.50942434e-01, 3.48898342e-01],\n",
       "       [2.69927892e-01, 8.95886218e-01],\n",
       "       [4.28091190e-01, 9.64840047e-01],\n",
       "       [6.63441498e-01, 6.21695720e-01],\n",
       "       [1.14745973e-01, 9.49489259e-01],\n",
       "       [4.49912133e-01, 5.78389614e-01],\n",
       "       [4.08136803e-01, 2.37026980e-01],\n",
       "       [9.03379521e-01, 5.73679487e-01],\n",
       "       [2.87032703e-03, 6.17144914e-01],\n",
       "       [3.26644902e-01, 5.27058102e-01],\n",
       "       [8.85942099e-01, 3.57269760e-01],\n",
       "       [9.08535151e-01, 6.23360116e-01],\n",
       "       [1.58212428e-02, 9.29437234e-01],\n",
       "       [6.90896918e-01, 9.97322850e-01],\n",
       "       [1.72340508e-01, 1.37135750e-01],\n",
       "       [9.32595463e-01, 6.96818161e-01],\n",
       "       [6.60001727e-02, 7.55463053e-01],\n",
       "       [7.53876188e-01, 9.23024536e-01],\n",
       "       [7.11524759e-01, 1.24270962e-01],\n",
       "       [1.98801338e-02, 2.62109869e-02],\n",
       "       [2.83064880e-02, 2.46211068e-01],\n",
       "       [8.60027949e-01, 5.38831064e-01],\n",
       "       [5.52821979e-01, 8.42030892e-01],\n",
       "       [1.24173315e-01, 2.79183679e-01],\n",
       "       [5.85759271e-01, 9.69595748e-01],\n",
       "       [5.61030219e-01, 1.86472894e-02],\n",
       "       [8.00632673e-01, 2.32974274e-01],\n",
       "       [8.07105196e-01, 3.87860644e-01],\n",
       "       [8.63541855e-01, 7.47121643e-01],\n",
       "       [5.56240234e-01, 1.36455226e-01],\n",
       "       [5.99176895e-02, 1.21343456e-01],\n",
       "       [4.45518785e-02, 1.07494129e-01],\n",
       "       [2.25709339e-01, 7.12988980e-01],\n",
       "       [5.59716982e-01, 1.25559802e-02],\n",
       "       [7.19742797e-02, 9.67276330e-01],\n",
       "       [5.68100462e-01, 2.03293235e-01],\n",
       "       [2.52325745e-01, 7.43825854e-01],\n",
       "       [1.95429481e-01, 5.81358927e-01],\n",
       "       [9.70019989e-01, 8.46828801e-01],\n",
       "       [2.39847759e-01, 4.93769714e-01],\n",
       "       [6.19955718e-01, 8.28980900e-01],\n",
       "       [1.56791395e-01, 1.85762022e-02],\n",
       "       [7.00221437e-02, 4.86345111e-01],\n",
       "       [6.06329462e-01, 5.68851437e-01],\n",
       "       [3.17362409e-01, 9.88616154e-01],\n",
       "       [5.79745219e-01, 3.80141173e-01],\n",
       "       [5.50948219e-01, 7.45334431e-01],\n",
       "       [6.69232893e-01, 2.64919558e-01],\n",
       "       [6.63348344e-02, 3.70084198e-01],\n",
       "       [6.29717507e-01, 2.10174010e-01],\n",
       "       [7.52755554e-01, 6.65364814e-02],\n",
       "       [2.60315099e-01, 8.04754564e-01],\n",
       "       [1.93434283e-01, 6.39460881e-01],\n",
       "       [5.24670309e-01, 9.24807970e-01],\n",
       "       [2.63296770e-01, 6.59610907e-02],\n",
       "       [7.35065963e-01, 7.72178030e-01],\n",
       "       [9.07815853e-01, 9.31972069e-01],\n",
       "       [1.39515730e-02, 2.34362086e-01],\n",
       "       [6.16778357e-01, 9.49016321e-01],\n",
       "       [9.50176119e-01, 5.56653188e-01],\n",
       "       [9.15606350e-01, 6.41566209e-01],\n",
       "       [3.90007714e-01, 4.85990667e-01],\n",
       "       [6.04310483e-01, 5.49547922e-01],\n",
       "       [9.26181427e-01, 9.18733436e-01],\n",
       "       [3.94875613e-01, 9.63262528e-01],\n",
       "       [1.73955667e-01, 1.26329519e-01],\n",
       "       [1.35079158e-01, 5.05662166e-01],\n",
       "       [2.15248053e-02, 9.47970211e-01],\n",
       "       [8.27115471e-01, 1.50189807e-02],\n",
       "       [1.76196256e-01, 3.32063574e-01],\n",
       "       [1.30996845e-01, 8.09490692e-01],\n",
       "       [3.44736653e-01, 9.40107482e-01],\n",
       "       [5.82014180e-01, 8.78831984e-01],\n",
       "       [8.44734445e-01, 9.05392319e-01],\n",
       "       [4.59880266e-01, 5.46346816e-01],\n",
       "       [7.98603591e-01, 2.85718852e-01],\n",
       "       [4.90253523e-01, 5.99110308e-01],\n",
       "       [1.55332756e-02, 5.93481408e-01],\n",
       "       [4.33676349e-01, 8.07360529e-01],\n",
       "       [3.15244803e-01, 8.92888709e-01],\n",
       "       [5.77857215e-01, 1.84010202e-01],\n",
       "       [7.87929234e-01, 6.12031177e-01],\n",
       "       [5.39092721e-02, 4.20193680e-01],\n",
       "       [6.79068837e-01, 9.18601778e-01],\n",
       "       [4.02024891e-04, 9.76759149e-01],\n",
       "       [3.76580315e-01, 9.73783538e-01],\n",
       "       [6.04716101e-01, 8.28845808e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import RandomState\n",
    "batch_size = 8\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,2],name='x-input')\n",
    "\n",
    "y_ = tf.placeholder(tf.float32,[None,1],name='y-input')\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))\n",
    "y = tf.matmul(x,w1)\n",
    "\n",
    "# 定义预测多了和少了的成本\n",
    "loss_less = 10\n",
    "loss_more = 1\n",
    "\n",
    "loss = tf.reduce_mean(tf.where(tf.greater(y,y_),(y-y_)*loss_more,(y_-y)*loss_less))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "Y = [[x1+x2+rdm.rand()/10.0-0.5] for x1,x2 in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6457671 ]\n",
      " [0.82601607]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    for i in range(5001):\n",
    "        start = (i*batch_size) % dataset_size\n",
    "        end = min(start + batch_size,dataset_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数衰减学习率\n",
    "global_step = tf.Variable(0)\n",
    "# 通过exponential_decay函数生成学习率\n",
    "learning_rate = tf.train.exponential_decay(0.1,global_step=global_step,100,0.96,staircase=True)\n",
    "# 使用指数衰减的学习率。在minimize函数中传入global_step将自动更新global_step参数，从而使得学习率也相应更新\n",
    "learning_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "\n",
    "# 设定初始学习率为0.1，staircase=True设置为True，每迭代10次，学习率乘以0.96."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
