{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578]]\n"
     ]
    }
   ],
   "source": [
    "# 利用placeholder\n",
    "w1 = tf.Variable(tf.random_normal((2,3),stddev=1,seed=1),name='w1')\n",
    "w2 = tf.Variable(tf.random_normal((3,1),stddev=1,seed=1),name='w2')\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=(1,2),name='input')\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op=tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "# print(sess.run(y))\n",
    "'''\n",
    "使用placeholder，run时需要feed_dict对它赋值\n",
    "InvalidArgumentError: You must feed a value for placeholder tensor 'input' with dtype float and shape [1,2]\n",
    "\t [[Node: input = Placeholder[dtype=DT_FLOAT, shape=[1,2], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
    "'''\n",
    "print(sess.run(y,feed_dict={x:[[0.7,0.9]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578 ]\n",
      " [1.1537654]\n",
      " [3.1674924]]\n"
     ]
    }
   ],
   "source": [
    "# 利用placeholder\n",
    "w1 = tf.Variable(tf.random_normal((2,3),stddev=1,seed=1),name='w1')\n",
    "w2 = tf.Variable(tf.random_normal((3,1),stddev=1,seed=1),name='w2')\n",
    "# n x 2矩阵，每次一个batch的数据输入\n",
    "x = tf.placeholder(tf.float32,shape=(3,2),name='input')\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op=tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "# run时要根据x定义，输入数据\n",
    "print(sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.17022005e-01, 7.20324493e-01],\n",
       "       [1.14374817e-04, 3.02332573e-01],\n",
       "       [1.46755891e-01, 9.23385948e-02],\n",
       "       [1.86260211e-01, 3.45560727e-01],\n",
       "       [3.96767474e-01, 5.38816734e-01],\n",
       "       [4.19194514e-01, 6.85219500e-01],\n",
       "       [2.04452250e-01, 8.78117436e-01],\n",
       "       [2.73875932e-02, 6.70467510e-01],\n",
       "       [4.17304802e-01, 5.58689828e-01],\n",
       "       [1.40386939e-01, 1.98101489e-01],\n",
       "       [8.00744569e-01, 9.68261576e-01],\n",
       "       [3.13424178e-01, 6.92322616e-01],\n",
       "       [8.76389152e-01, 8.94606664e-01],\n",
       "       [8.50442114e-02, 3.90547832e-02],\n",
       "       [1.69830420e-01, 8.78142503e-01],\n",
       "       [9.83468338e-02, 4.21107625e-01],\n",
       "       [9.57889530e-01, 5.33165285e-01],\n",
       "       [6.91877114e-01, 3.15515631e-01],\n",
       "       [6.86500928e-01, 8.34625672e-01],\n",
       "       [1.82882773e-02, 7.50144315e-01],\n",
       "       [9.88861089e-01, 7.48165654e-01],\n",
       "       [2.80443992e-01, 7.89279328e-01],\n",
       "       [1.03226007e-01, 4.47893526e-01],\n",
       "       [9.08595503e-01, 2.93614148e-01],\n",
       "       [2.87775339e-01, 1.30028572e-01],\n",
       "       [1.93669579e-02, 6.78835533e-01],\n",
       "       [2.11628116e-01, 2.65546659e-01],\n",
       "       [4.91573159e-01, 5.33625451e-02],\n",
       "       [5.74117605e-01, 1.46728575e-01],\n",
       "       [5.89305537e-01, 6.99758360e-01],\n",
       "       [1.02334429e-01, 4.14055988e-01],\n",
       "       [6.94400158e-01, 4.14179270e-01],\n",
       "       [4.99534589e-02, 5.35896406e-01],\n",
       "       [6.63794645e-01, 5.14889112e-01],\n",
       "       [9.44594756e-01, 5.86555041e-01],\n",
       "       [9.03401915e-01, 1.37474704e-01],\n",
       "       [1.39276347e-01, 8.07391289e-01],\n",
       "       [3.97676837e-01, 1.65354197e-01],\n",
       "       [9.27508580e-01, 3.47765860e-01],\n",
       "       [7.50812103e-01, 7.25997985e-01],\n",
       "       [8.83306091e-01, 6.23672207e-01],\n",
       "       [7.50942434e-01, 3.48898342e-01],\n",
       "       [2.69927892e-01, 8.95886218e-01],\n",
       "       [4.28091190e-01, 9.64840047e-01],\n",
       "       [6.63441498e-01, 6.21695720e-01],\n",
       "       [1.14745973e-01, 9.49489259e-01],\n",
       "       [4.49912133e-01, 5.78389614e-01],\n",
       "       [4.08136803e-01, 2.37026980e-01],\n",
       "       [9.03379521e-01, 5.73679487e-01],\n",
       "       [2.87032703e-03, 6.17144914e-01],\n",
       "       [3.26644902e-01, 5.27058102e-01],\n",
       "       [8.85942099e-01, 3.57269760e-01],\n",
       "       [9.08535151e-01, 6.23360116e-01],\n",
       "       [1.58212428e-02, 9.29437234e-01],\n",
       "       [6.90896918e-01, 9.97322850e-01],\n",
       "       [1.72340508e-01, 1.37135750e-01],\n",
       "       [9.32595463e-01, 6.96818161e-01],\n",
       "       [6.60001727e-02, 7.55463053e-01],\n",
       "       [7.53876188e-01, 9.23024536e-01],\n",
       "       [7.11524759e-01, 1.24270962e-01],\n",
       "       [1.98801338e-02, 2.62109869e-02],\n",
       "       [2.83064880e-02, 2.46211068e-01],\n",
       "       [8.60027949e-01, 5.38831064e-01],\n",
       "       [5.52821979e-01, 8.42030892e-01],\n",
       "       [1.24173315e-01, 2.79183679e-01],\n",
       "       [5.85759271e-01, 9.69595748e-01],\n",
       "       [5.61030219e-01, 1.86472894e-02],\n",
       "       [8.00632673e-01, 2.32974274e-01],\n",
       "       [8.07105196e-01, 3.87860644e-01],\n",
       "       [8.63541855e-01, 7.47121643e-01],\n",
       "       [5.56240234e-01, 1.36455226e-01],\n",
       "       [5.99176895e-02, 1.21343456e-01],\n",
       "       [4.45518785e-02, 1.07494129e-01],\n",
       "       [2.25709339e-01, 7.12988980e-01],\n",
       "       [5.59716982e-01, 1.25559802e-02],\n",
       "       [7.19742797e-02, 9.67276330e-01],\n",
       "       [5.68100462e-01, 2.03293235e-01],\n",
       "       [2.52325745e-01, 7.43825854e-01],\n",
       "       [1.95429481e-01, 5.81358927e-01],\n",
       "       [9.70019989e-01, 8.46828801e-01],\n",
       "       [2.39847759e-01, 4.93769714e-01],\n",
       "       [6.19955718e-01, 8.28980900e-01],\n",
       "       [1.56791395e-01, 1.85762022e-02],\n",
       "       [7.00221437e-02, 4.86345111e-01],\n",
       "       [6.06329462e-01, 5.68851437e-01],\n",
       "       [3.17362409e-01, 9.88616154e-01],\n",
       "       [5.79745219e-01, 3.80141173e-01],\n",
       "       [5.50948219e-01, 7.45334431e-01],\n",
       "       [6.69232893e-01, 2.64919558e-01],\n",
       "       [6.63348344e-02, 3.70084198e-01],\n",
       "       [6.29717507e-01, 2.10174010e-01],\n",
       "       [7.52755554e-01, 6.65364814e-02],\n",
       "       [2.60315099e-01, 8.04754564e-01],\n",
       "       [1.93434283e-01, 6.39460881e-01],\n",
       "       [5.24670309e-01, 9.24807970e-01],\n",
       "       [2.63296770e-01, 6.59610907e-02],\n",
       "       [7.35065963e-01, 7.72178030e-01],\n",
       "       [9.07815853e-01, 9.31972069e-01],\n",
       "       [1.39515730e-02, 2.34362086e-01],\n",
       "       [6.16778357e-01, 9.49016321e-01],\n",
       "       [9.50176119e-01, 5.56653188e-01],\n",
       "       [9.15606350e-01, 6.41566209e-01],\n",
       "       [3.90007714e-01, 4.85990667e-01],\n",
       "       [6.04310483e-01, 5.49547922e-01],\n",
       "       [9.26181427e-01, 9.18733436e-01],\n",
       "       [3.94875613e-01, 9.63262528e-01],\n",
       "       [1.73955667e-01, 1.26329519e-01],\n",
       "       [1.35079158e-01, 5.05662166e-01],\n",
       "       [2.15248053e-02, 9.47970211e-01],\n",
       "       [8.27115471e-01, 1.50189807e-02],\n",
       "       [1.76196256e-01, 3.32063574e-01],\n",
       "       [1.30996845e-01, 8.09490692e-01],\n",
       "       [3.44736653e-01, 9.40107482e-01],\n",
       "       [5.82014180e-01, 8.78831984e-01],\n",
       "       [8.44734445e-01, 9.05392319e-01],\n",
       "       [4.59880266e-01, 5.46346816e-01],\n",
       "       [7.98603591e-01, 2.85718852e-01],\n",
       "       [4.90253523e-01, 5.99110308e-01],\n",
       "       [1.55332756e-02, 5.93481408e-01],\n",
       "       [4.33676349e-01, 8.07360529e-01],\n",
       "       [3.15244803e-01, 8.92888709e-01],\n",
       "       [5.77857215e-01, 1.84010202e-01],\n",
       "       [7.87929234e-01, 6.12031177e-01],\n",
       "       [5.39092721e-02, 4.20193680e-01],\n",
       "       [6.79068837e-01, 9.18601778e-01],\n",
       "       [4.02024891e-04, 9.76759149e-01],\n",
       "       [3.76580315e-01, 9.73783538e-01],\n",
       "       [6.04716101e-01, 8.28845808e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 完整的神经网络demo\n",
    "# 加入激活函数\n",
    "# 定义loss\n",
    "# 根据最小化loss 优化参数，迭代更新\n",
    "from numpy.random import RandomState\n",
    "\n",
    "# 定义batch的大小\n",
    "batch_size = 8\n",
    "# 定义参数\n",
    "w1 = tf.Variable(tf.random_normal((2,3),stddev=1,seed=1),name='w1')\n",
    "w2 = tf.Variable(tf.random_normal((3,1),stddev=1,seed=1),name='w2')\n",
    "\n",
    "# 在shape上使用None可以方便的使用不同batch的大小\n",
    "x = tf.placeholder(tf.float32,shape=(None,2),name='x-input')\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1),name='y-input')\n",
    "# 定义神经网络的前向传播过程\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "#定义损失函数和 反向传播算法\n",
    "y = tf.sigmoid(y)\n",
    "# 使用交叉熵作为损失函数\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y,1e-10,1.0)) + (1-y_)*tf.log(tf.clip_by_value(1-y,1e-10,1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "# 随机生成一个数据集，模拟输入数据\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "# X  128 行 2列的一组想输入数据，矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = [[int(x1 + x2 < 1)] for x1,x2 in X]\n",
    "# Y 定义规则 给出y标签数据，这里x1 + x2 < 1的数据认为是正例，否则是负例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "[[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "After 0 training step(s),cross_entropy on all data is 1.89805\n",
      "After 100 training step(s),cross_entropy on all data is 1.62943\n",
      "After 200 training step(s),cross_entropy on all data is 1.40099\n",
      "After 300 training step(s),cross_entropy on all data is 1.19732\n",
      "After 400 training step(s),cross_entropy on all data is 1.02375\n",
      "After 500 training step(s),cross_entropy on all data is 0.887612\n",
      "After 600 training step(s),cross_entropy on all data is 0.790222\n",
      "After 700 training step(s),cross_entropy on all data is 0.727325\n",
      "After 800 training step(s),cross_entropy on all data is 0.689437\n",
      "After 900 training step(s),cross_entropy on all data is 0.667623\n",
      "After 1000 training step(s),cross_entropy on all data is 0.655075\n",
      "After 1100 training step(s),cross_entropy on all data is 0.647813\n",
      "After 1200 training step(s),cross_entropy on all data is 0.643196\n",
      "After 1300 training step(s),cross_entropy on all data is 0.639896\n",
      "After 1400 training step(s),cross_entropy on all data is 0.637246\n",
      "After 1500 training step(s),cross_entropy on all data is 0.635031\n",
      "After 1600 training step(s),cross_entropy on all data is 0.633027\n",
      "After 1700 training step(s),cross_entropy on all data is 0.631151\n",
      "After 1800 training step(s),cross_entropy on all data is 0.629368\n",
      "After 1900 training step(s),cross_entropy on all data is 0.627724\n",
      "After 2000 training step(s),cross_entropy on all data is 0.626172\n",
      "After 2100 training step(s),cross_entropy on all data is 0.624697\n",
      "After 2200 training step(s),cross_entropy on all data is 0.623293\n",
      "After 2300 training step(s),cross_entropy on all data is 0.622006\n",
      "After 2400 training step(s),cross_entropy on all data is 0.620801\n",
      "After 2500 training step(s),cross_entropy on all data is 0.619664\n",
      "After 2600 training step(s),cross_entropy on all data is 0.618592\n",
      "After 2700 training step(s),cross_entropy on all data is 0.617622\n",
      "After 2800 training step(s),cross_entropy on all data is 0.616723\n",
      "After 2900 training step(s),cross_entropy on all data is 0.615883\n",
      "After 3000 training step(s),cross_entropy on all data is 0.615096\n",
      "After 3100 training step(s),cross_entropy on all data is 0.614397\n",
      "After 3200 training step(s),cross_entropy on all data is 0.613756\n",
      "After 3300 training step(s),cross_entropy on all data is 0.61316\n",
      "After 3400 training step(s),cross_entropy on all data is 0.612608\n",
      "After 3500 training step(s),cross_entropy on all data is 0.612126\n",
      "After 3600 training step(s),cross_entropy on all data is 0.611688\n",
      "After 3700 training step(s),cross_entropy on all data is 0.611285\n",
      "After 3800 training step(s),cross_entropy on all data is 0.610913\n",
      "After 3900 training step(s),cross_entropy on all data is 0.610594\n",
      "After 4000 training step(s),cross_entropy on all data is 0.610309\n",
      "After 4100 training step(s),cross_entropy on all data is 0.610046\n",
      "After 4200 training step(s),cross_entropy on all data is 0.609804\n",
      "After 4300 training step(s),cross_entropy on all data is 0.609603\n",
      "After 4400 training step(s),cross_entropy on all data is 0.609423\n",
      "After 4500 training step(s),cross_entropy on all data is 0.609258\n",
      "After 4600 training step(s),cross_entropy on all data is 0.609106\n",
      "After 4700 training step(s),cross_entropy on all data is 0.608983\n",
      "After 4800 training step(s),cross_entropy on all data is 0.608874\n",
      "After 4900 training step(s),cross_entropy on all data is 0.608772\n",
      "After 5000 training step(s),cross_entropy on all data is 0.608679\n",
      "[[ 0.02494928  0.5693592   1.6923722 ]\n",
      " [-2.1976933  -0.23671868  1.1144308 ]]\n",
      "[[-0.45541054]\n",
      " [ 0.49095193]\n",
      " [-0.98123735]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化参数\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    # 最初的参数\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    # 设定训练的轮数\n",
    "    STEPS = 5001\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size) % dataset_size\n",
    "        end = min(start + batch_size,dataset_size)\n",
    "        # 训练过程\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        if i % 100 == 0:\n",
    "            # 每迭代100次打印出交叉熵\n",
    "            total_cross_entropy = sess.run(cross_entropy,feed_dict={x:X,y_:Y})\n",
    "            print(\"After %d training step(s),cross_entropy on all data is %g\" %(i,total_cross_entropy))\n",
    "    # 训练5001次后的参数 跟前面对比下\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
